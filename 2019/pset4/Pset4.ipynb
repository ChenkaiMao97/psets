{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 4: Physiological Signals\n",
    "\n",
    "In this problem set, we will explore the process of using multivariate time series data from vital signs from MIMIC-III. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Vital signals are vital\n",
    "\n",
    "We have provided vitals information from the MIMIC-III dataset. In particular, we have provided vitals for patients from the first 24 hours for the following vitals\n",
    " - Heart rate in bpm \n",
    " - Respiratory rate in breaths / minute \n",
    " - Pulse oximetry \n",
    " - Mean arterial pressure\n",
    " - Systolic blood pressure in mmHg \n",
    " - Diastolic blood pressure in mmHg \n",
    " - Glucose reading\n",
    " - Temperature\n",
    "\n",
    "We have aggregated each vital signal into the min/max/mean of that hour. Because not all vital signs are measured at the same rate, missing values are designated as NaN. If no vital signs were measured in that hour, the patient ICU stay will have no row for that hour. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vitals_24h.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 \n",
    "\n",
    "How many rows are in vitals_24h.csv? For each of the vital types, how many vital signs are there per patient ICU stay on average? Plot the distribution of values across patient ICU stays for each vital sign using histograms with 40 bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 \n",
    "\n",
    "We want to model patients with ICU stays where we have hourly readings for the first 24 hours. Patients with ICU stays where measures aren’t recorded have been marked as null. \n",
    "\n",
    " - How many patient ICU stays are included in this dataset in any form?\n",
    " - How many patients ICU stays show up with 24 hours of measurements, even if some of the hours have some missing values? \n",
    " - How many patients ICU stays have 24 hours measurements with all present measurements? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 \n",
    "\n",
    "In order to increase the number of include patient ICU stays, we want to keep vital readings that appear >80% of the time over all rows in vitals_24h.csv. Which vitals would we keep? Which vitals would we remove?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 \n",
    "\n",
    "For the rest of the problem set, we will keep vitals that appear >80% of the time across all rows, but that is only one way to handle missing data. Besides throwing out rows that are incomplete, what are three other ways we can impute missing data for multivariate time series modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LSTM time\n",
    "\n",
    "Let's build an LSTM!\n",
    "\n",
    "## 2.1 \n",
    "\n",
    "We are interested in using this time series information to model patient care. Keep vitals that appear in >80% the rows. **How many patient ICU stays are in the dataset?** \n",
    "\n",
    "We want to analyze patient ICU stays that last longer than 48 hours by predicting from the first 24 hours, but vitals_24h.csv includes vitals from all patients in the MIMIC dataset. Join with demo.csv. **How many patients are left in the dataset now?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data tensor of shape: [n_samples, n_timesteps, n_features] for data labeled train, valid, and test. Data should be scaled using MinMaxScaler from sklearn using feature_range=(0,1) across the entire dataset before being separated into train, valid, and test. \n",
    "\n",
    "You may find it helpful to create column names of the form: t00_heartrate_min, t00_heartrate_max, …, t23_heartrate_max, …\n",
    "\n",
    "We often find that sex and age are predictive features. Encode sex as a “is_female” feature. Include age and sex in the tensor: t00_is_female, t00_age, …, t23_is_female, t23_age. Note that t00_age, …, t23_age will all be the same and similar with the sex features. These features can be found in demo.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create data tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 \n",
    "\n",
    "Build an LSTM using Keras for multivariate time series classification. Use an LSTM with:\n",
    " - 20 units\n",
    " - a dense layer with sigmoid activation\n",
    " - binary cross-entropy loss\n",
    " - ADAM optimizer\n",
    " - Dropout of 0.2\n",
    " - 100 epochs\n",
    " - Batch size of 128\n",
    "\n",
    "You may find these guides helpful:\n",
    " - [Multivariate time series forecasting for regression](https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/)\n",
    " - [Sequence classification using LSTMs](https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/)\n",
    "\n",
    "What is the train loss, accuracy, and AUC? Experiment with Dropout = [0.0,0.2,0.5, 0.8] by comparing the AUC on the validation data. What Dropout value yields the best AUC on the validation data? Using this best Dropout value, what is the corresponding test AUC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3\n",
    "\n",
    "Select two patient ICU stays for whom the LSTM predicts the patient ICU stay will end in patient mortality and two patient ICU stays for whom the LSTM predicts the patient ICU stay will NOT end in patient mortality. Plot any vital features that are particularly meaningful over time and describe any noticeable differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear baseline\n",
    "\n",
    "Whenever we use more sophisticated deep learning models, we want to compare against a simpler baseline to make sure the computational effort is worth it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "\n",
    "What is Logistic Regression with just the raw values from 2.2? You should use a matrix of shape [n_shapes, n_timesteps * n_features], which is an unrolled version of the data tensor from earlier. You can keep age and sex in their time-multiplied form or only include them once. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 \n",
    "\n",
    "Hyperparameter tune on C=[0.01,0.1,0.5,1.0, 5.0] and penalty=[‘l1’,’l2’] by comparing the AUC on the validation data. What are the best hyperparameters on the validation data? What is the test AUC using these best hyperparameters? How does this compare to the results from 2.2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 3.2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
